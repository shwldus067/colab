{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tagging Task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzSlzQH0sVsOEIZxnMtaJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shwldus067/colab/blob/main/Tagging_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI9fFfaFXnQi"
      },
      "source": [
        "<h1><b>태깅 작업</b></h1>\n",
        "각 단어가 어떤 유형에 속하는지를 알아내는 작업\n",
        "<ul>\n",
        "<li>개체명 인식(Named Entity Recognition): 단어의 유형이 사람, 장소, 단체 등 어떤 유형인지 알아낸다.</li>\n",
        "<li>품사 태깅(Part-of_speech Tagging): 각 단어의 품사가 명사, 동사, 형용사 인지를 알아낸다.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCRO1ikPYwf3"
      },
      "source": [
        "<h2>1. 케라스를 이용한 태깅 작업</h2>\n",
        "개체명 인식기와 품사 태거를 만든다. RNN의 Many-to-Many 작업이면서 앞, 뒤 시점의 입력을 모두 참고하는 RNN(Bidirectional RNN)을 사용한다.\n",
        "<ul>\n",
        "<li><h3>훈련 데이터</h3>\n",
        "X:태깅해야하는 단어 데이터<p>\n",
        "y:레이블에 해당되는 태깅 정보<p>\n",
        "X와 y데이터의 쌍은 병렬 구조를 갖는다. 정수 인코딩 후 패딩 작업을 거친다.\n",
        "</li>\n",
        "<li><h3>시퀀스 레이블링</h3>\n",
        "X = [x1, x2, x3, ...,xn]에 대하여 레이블 시퀀스 y = [y1, y2, y3, ...,yn]를 각각 부여하는 작업<p>\n",
        "태깅은 대표적인 시퀀스 레이블링 작업이다.\n",
        "</li>\n",
        "<li><h3>양방향 LSTM</h3>\n",
        "이전 시점의 단어 정보와 다음 시점의 단어 정보도 참고하기 위해 Bidirectional LSTM을 사용한다. 기존의 단방향 LSTM()을 Bidirectional()안에 넣으면 된다.\n",
        "\n",
        "```\n",
        "model.add(Bidirectional(LSTM(hidden_size, return_sequences=True)))\n",
        "```\n",
        "</li>\n",
        "<li><h3>RNN의 Many-to-Many 문제</h3>\n",
        "태깅 작업할 때 Many-to-Many 문제로 return_sequences=True를 설정해 출력층에 모든 은닉 상태값을 보낸다.<p>\n",
        "<img src=\"https://wikidocs.net/images/page/33805/forwardrnn_ver2.PNG\"></img>\n",
        "<p>양방향 RNN을 사용할 경우<p>\n",
        "<img src=\"https://wikidocs.net/images/page/33805/bidirectionalrnn_ver2.PNG\"></img>\n",
        "</li>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMHgATTIe_A8"
      },
      "source": [
        "<h2>2. 양방향 LSTM을 이용한 품사 태깅</h2>\n",
        "직접 양방향 LSTM을 이용한 품사 태깅을 수행하는 모델 생성\n",
        "<ul>\n",
        "<li><h3>품사 태깅 데이터에 대한 이해와 전처리</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vicl7Zu7c6_e"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "# nltk로 영어 코퍼스에 토큰화와 품사 태깅 전처리를 진행한 문장 데이터를 받아올 수 있다."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHjhdyQegqK8",
        "outputId": "eaf41d16-ff37-45e7-bc68-03fff239ed5b"
      },
      "source": [
        "nltk.download('treebank')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yooZEvVigDmX",
        "outputId": "4be6346c-236d-45a2-eebb-57458cc90bad"
      },
      "source": [
        "# 토큰화에 품사 태깅된 데이터 받아오기\n",
        "tagged_sentences=nltk.corpus.treebank.tagged_sents()\n",
        "# 문장 샘플의 개수 출력\n",
        "print(\"품사 태깅이 된 문장 개수: \", len(tagged_sentences))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "품사 태깅이 된 문장 개수:  3914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Foi-7jQLgfG2",
        "outputId": "6dcd3c5e-ab9a-4348-9d75-359b081ba793"
      },
      "source": [
        "# 첫 번째 샘플 출력\n",
        "print(tagged_sentences[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2jjBPT4gyAh"
      },
      "source": [
        "# 단어에 해당되는 부분과 품사 태깅 정보에 해당되는 부분 분리\n",
        "sentences, pos_tags=[],[]\n",
        "for tagged_sentence in tagged_sentences:\n",
        "  sentence, tag_info=zip(*tagged_sentence)  # 단어들, 태깅 정보\n",
        "  sentences.append(list(sentence))\n",
        "  pos_tags.append(list(tag_info))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvVIDuD1hapo",
        "outputId": "da4c400a-7ac9-409e-a3d8-ee5879624472"
      },
      "source": [
        "print(sentences[0])\n",
        "print(pos_tags[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Iwds5girhgBJ",
        "outputId": "17985661-12af-468f-eddc-ae53dfcbda35"
      },
      "source": [
        "# 전체 데이터의 길이 분포\n",
        "# 대부분 0~50의 길이를 갖는다.\n",
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 271\n",
            "샘플의 평균 길이 : 25.722024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T13GktMWiU35"
      },
      "source": [
        "# keras tokenizer\n",
        "def tokenize(samples):\n",
        "  tokenizer=Tokenizer()\n",
        "  tokenizer.fit_on_texts(samples)\n",
        "  return tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYxS9h5cijGR"
      },
      "source": [
        "# 문장 데이터와 품사 태깅 정보 토크나이저\n",
        "src_tokenizer=tokenize(sentences)\n",
        "tar_tokenizer=tokenize(pos_tags)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRtx-kuNisVz",
        "outputId": "3203d9bc-7ec3-4e30-d58b-030cb58dda6c"
      },
      "source": [
        "# 단어 집합과 품사 태깅 정보 집합의 크기\n",
        "vocab_size=len(src_tokenizer.word_index)+1\n",
        "tag_size=len(tar_tokenizer.word_index)+1\n",
        "print('단어 집합의 크기:{}'.format(vocab_size))\n",
        "print('태깅 정보 집합의 크기:{}'.format(tag_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기:11388\n",
            "태깅 정보 집합의 크기:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWF2QRh2i_6m"
      },
      "source": [
        "# 정수 인코딩\n",
        "X_train=src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train=tar_tokenizer.texts_to_sequences(pos_tags)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3ArI3dVkz6x",
        "outputId": "c46a6346-0d28-489e-fabf-98e9cb7a4184"
      },
      "source": [
        "print(X_train[:2])\n",
        "print(y_train[:2])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3], [31, 3746, 20, 177, 4, 5602, 2915, 1, 2, 2916, 637, 147, 3]]\n",
            "[[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9], [3, 3, 17, 1, 2, 3, 3, 8, 4, 3, 19, 1, 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSmssfpclN51"
      },
      "source": [
        "# 샘플의 길이를 150으로 맞춰 padding\n",
        "max_len=150\n",
        "X_train=pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "y_train=pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8eamvUEloZS"
      },
      "source": [
        "# split train:test=8:2\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_train, y_train, test_size=.2, random_state=777)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu3CzfUwl1pI"
      },
      "source": [
        "# one-hot encoding\n",
        "y_train=to_categorical(y_train, num_classes=tag_size)\n",
        "y_test=to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lgu49ddl9V1",
        "outputId": "891badcf-cdbc-46af-da8d-f63366b61563"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (3131, 150)\n",
            "훈련 샘플 레이블의 크기 : (3131, 150, 47)\n",
            "테스트 샘플 문장의 크기 : (783, 150)\n",
            "테스트 샘플 레이블의 크기 : (783, 150, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5lWrD_qmU9U"
      },
      "source": [
        "<ul>\n",
        "<li><h3>양방향 LSTM으로 POS Tagger 만들기</h3></li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxLmcoTmeSU"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWBRN4psmz75"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtP0BK5rnK68",
        "outputId": "b7c0b77b-f58a-4719-d830-42583443d8b8"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=6, validation_data=(X_test, y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "25/25 [==============================] - 29s 313ms/step - loss: 0.5716 - accuracy: 0.1460 - val_loss: 0.5050 - val_accuracy: 0.1617\n",
            "Epoch 2/6\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.4878 - accuracy: 0.2435 - val_loss: 0.4521 - val_accuracy: 0.3821\n",
            "Epoch 3/6\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.3909 - accuracy: 0.4510 - val_loss: 0.3079 - val_accuracy: 0.5380\n",
            "Epoch 4/6\n",
            "25/25 [==============================] - 2s 88ms/step - loss: 0.2417 - accuracy: 0.6403 - val_loss: 0.1771 - val_accuracy: 0.7604\n",
            "Epoch 5/6\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.1268 - accuracy: 0.8401 - val_loss: 0.0987 - val_accuracy: 0.8637\n",
            "Epoch 6/6\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.0661 - accuracy: 0.9173 - val_loss: 0.0652 - val_accuracy: 0.9044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffb24d87150>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lWxs4-ynRrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66306e71-559a-4400-b627-a8f3a667e857"
      },
      "source": [
        "print(\"\\n테스트 정확도: %.4f\"%(model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 17ms/step - loss: 0.0652 - accuracy: 0.9044\n",
            "\n",
            "테스트 정확도: 0.9044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k-RzPomwZUG",
        "outputId": "eb9c22dc-b04b-4b89-fc42-92819b508f2a"
      },
      "source": [
        "# 단어와 품사 태깅 정보 리턴\n",
        "index_to_word=src_tokenizer.index_word\n",
        "index_to_tag=tar_tokenizer.index_word\n",
        "\n",
        "i=10  # 확인할 테스트 샘플의 인덱스\n",
        "y_predicted=model.predict(np.array([X_test[i]]))\n",
        "\n",
        "# one-hot encoding을 정수 인코딩으로 변환\n",
        "y_predicted=np.argmax(y_predicted, axis=-1)\n",
        "true=np.argmax(y_test[i], -1)\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_tag[t].upper(), index_to_tag[pred].upper()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "in               : IN      IN\n",
            "addition         : NN      NN\n",
            ",                : ,       ,\n",
            "buick            : NNP     NNP\n",
            "is               : VBZ     VBZ\n",
            "a                : DT      DT\n",
            "relatively       : RB      RB\n",
            "respected        : VBN     VBG\n",
            "nameplate        : NN      NN\n",
            "among            : IN      IN\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "card             : NN      NN\n",
            "holders          : NNS     NNS\n",
            ",                : ,       ,\n",
            "says             : VBZ     VBZ\n",
            "0                : -NONE-  -NONE-\n",
            "*t*-1            : -NONE-  -NONE-\n",
            "an               : DT      DT\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "spokeswoman      : NN      NN\n",
            ".                : .       .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxWF6ofYzU1Y"
      },
      "source": [
        "<ul>\n",
        "<li><h3>양방향 LSTM + CRF(Bi-directional LSTM + CRF)으로 POS tagger 만들기</h3>\n",
        "양방향 LSTM에 CRF layer를 추가해 성능을 높인다.\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IT_gagkx8wf",
        "outputId": "88edb463-b76a-4427-e2b3-6901497e3041"
      },
      "source": [
        "!pip install tf2crf"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf2crf\n",
            "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting tensorflow-addons>=0.8.2\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tf2crf) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.4.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.37.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.39.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (5.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1.0->tf2crf) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.34.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.4.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.1.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.5.0)\n",
            "Installing collected packages: tensorflow-addons, tf2crf\n",
            "Successfully installed tensorflow-addons-0.14.0 tf2crf-0.1.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opjmvNf6yqzi"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Input\n",
        "from tf2crf import CRF, ModelWithCRFLoss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-cqN59x0xh7",
        "outputId": "14f1579e-9d99-484b-d375-c585f21e5877"
      },
      "source": [
        "# 이전 모델에 CRF layer 추가\n",
        "inputs = Input(shape=(None,), dtype='int32')\n",
        "output = Embedding(vocab_size, 128, mask_zero=True)(inputs)\n",
        "output = Bidirectional(LSTM(128, return_sequences=True))(output)\n",
        "crf = CRF(tag_size)\n",
        "output = crf(output)\n",
        "base_model = Model(inputs, output)\n",
        "\n",
        "model = ModelWithCRFLoss(base_model, sparse_target=False)\n",
        "model.build(input_shape=(None, 22))\n",
        "model.compile(optimizer='adam')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
            "  return py_builtins.overload_of(f)(*args)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2XupZHX0zIE",
        "outputId": "606a5d2f-38ae-4e6c-a63e-39fad178357c"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 5, validation_split = 0.2, verbose = 1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
            "  return py_builtins.overload_of(f)(*args)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 67s 701ms/step - loss: 76.7042 - accuracy: 0.2508 - val_loss_val: 56.8613 - val_val_accuracy: 0.4756\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 52s 657ms/step - loss: 35.9907 - accuracy: 0.6533 - val_loss_val: 19.7528 - val_val_accuracy: 0.8272\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 51s 653ms/step - loss: 11.7635 - accuracy: 0.9005 - val_loss_val: 9.5466 - val_val_accuracy: 0.9039\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 51s 642ms/step - loss: 5.1243 - accuracy: 0.9569 - val_loss_val: 7.3160 - val_val_accuracy: 0.9189\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 51s 643ms/step - loss: 3.0251 - accuracy: 0.9732 - val_loss_val: 6.4752 - val_val_accuracy: 0.9256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-DEapCT1D6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b7071f-612e-4140-e8e9-66414305e07f"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 6s 250ms/step - loss_val: 6.3040 - val_accuracy: 0.9298\n",
            "\n",
            " 테스트 정확도: 0.9290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHaNyMIx1eIf"
      },
      "source": [
        "<h2>3. 개체명 인식(Named Entity Recognition)</h2>\n",
        "코퍼스에서 어떤 단어가 사람, 장소, 조직 등을 의미하는 단어인지를 찾는다.\n",
        "<ul>\n",
        "<li><h3>개체명 인식이란</h3>\n",
        "이름을 가진 개체를 인식한다. 단어가 어떤 유형인지를 인식한다. 전처리과정이 필요하고 모델에 따라 품사 정보를 입력으로 요구하기도 한다.\n",
        "</li>\n",
        "<li><h3>NLTK를 이용한 개체명 인식</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOg2E-lD2US8",
        "outputId": "037b7c8f-546e-49b3-e0b9-6cfa4ef8e35f"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OkPURtJ2Zzt",
        "outputId": "1b54467c-e153-4f2a-ec59-4d541d8c8e38"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xwgxAy21pQJ",
        "outputId": "e4f3a3a4-2f52-46fb-9fc0-83a47ca274cc"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "sentence = \"James is working at Disney in London\"\n",
        "sentence=pos_tag(word_tokenize(sentence))\n",
        "print(sentence) # 토큰화와 품사 태깅을 동시 수행"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apr_lRIr2h1i",
        "outputId": "300fd24c-c9c7-4c46-8317-84eee8566240"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFy4S6b82nVS",
        "outputId": "3a1ffdad-7648-48c9-a5f9-1a24941e091b"
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvMcguTI2S2S",
        "outputId": "68808350-b085-4008-f7cf-0a0e7be76003"
      },
      "source": [
        "sentence=ne_chunk(sentence) # 품사 태깅이 필요\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjEadEnm25qr"
      },
      "source": [
        "<h2>4. 개체명 인식의 BIO 표현</h2>\n",
        "직접 목적에 맞는 데이터를 준비해 훈련시켜 모델을 만드는 것이 더 개체명 인식을 정확하게 한다.\n",
        "<ul>\n",
        "<li><h3>BIO 표현</h3>\n",
        "IOB(또는 BIO): Begin(개체명이 시작되는 부분), Inside(개체명의 내부 부분), Outside(개체명이 아닌 부분)의 약자\n",
        "</li>\n",
        "<li><h3>개체명 인식 데이터</h3>\n",
        "양방향 LSTM을 이용한 개체명 인식<p>\n",
        "CONLL2003: 개체명 인식을 위한 전통적인 영어 데이터 셋<p>\n",
        "[단어] [품사태깅] [청크태깅] [개체명태깅]의 형식\n",
        "\n",
        "```\n",
        "EU NNP B-NP B-ORG\n",
        "rejects VBZ B-VP O\n",
        "German JJ B-NP B-MISC\n",
        "call NN I-NP O\n",
        "to TO B-VP O\n",
        "boycott VB I-VP O\n",
        "British JJ B-NP B-MISC\n",
        "lamb NN I-NP O\n",
        ". . O O\n",
        "\n",
        "Peter NNP B-NP B-PER\n",
        "Blackburn NNP I-NP I-PER\n",
        "```\n",
        "Peter Blackburn이 person에 속하는 하나의 개체명이다.\n",
        "\n",
        "</li\n",
        "<li><h3>데이터 전처리</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTG8cBAT2fbD"
      },
      "source": [
        "import re\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdLACQKA5JpI",
        "outputId": "fbe0f96e-84e8-491c-9d8a-3dad028144d8"
      },
      "source": [
        "from urllib import request\n",
        "# 데이터 다운로드\n",
        "request.urlretrieve('https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt', \"train.txt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('train.txt', <http.client.HTTPMessage at 0x7f4312e2d110>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si6hupzW5Cee"
      },
      "source": [
        "# 데이터 전처리\n",
        "f = open('/content/train.txt', 'r')\n",
        "tagged_sentences = []\n",
        "sentence = []\n",
        "\n",
        "for line in f:\n",
        "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "        if len(sentence) > 0:\n",
        "            tagged_sentences.append(sentence) # 문장별로 나눠서 저장\n",
        "            sentence = []\n",
        "        continue\n",
        "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
        "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
        "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
        "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hl97_DX6KOk",
        "outputId": "436c2df9-731e-4924-9273-a99a2cfda1d7"
      },
      "source": [
        "print(\"전체 샘플 개수: \", len(tagged_sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수:  14041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H46yttS662ud",
        "outputId": "dc7df081-a08a-42ab-8dc7-2895089e0088"
      },
      "source": [
        "print(tagged_sentences[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2mpWxFU64V-"
      },
      "source": [
        "# 단어와 개체명 태깅 분리\n",
        "sentences, ner_tags = [], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tag_info = zip(*tagged_sentence) # 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
        "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
        "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itxA8UCR7ESG",
        "outputId": "d93e6d44-4dce-473c-8280-d284242f0b03"
      },
      "source": [
        "# X:sentences, y:ner_tags로 사용된다.\n",
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
            "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vSfugR47zqf",
        "outputId": "5c53d1f5-2049-4ae8-b710-f161dfcd3674"
      },
      "source": [
        "print(sentences[12])\n",
        "print(ner_tags[12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['only', 'france', 'and', 'britain', 'backed', 'fischler', \"'s\", 'proposal', '.']\n",
            "['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "__STJwSA7-hy",
        "outputId": "3220a293-1a0b-49e2-a0c9-ee76f28c449f"
      },
      "source": [
        "# 데이터의 길이 분포\n",
        "# 대체로 0~40, 0~20이 대다수\n",
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 113\n",
            "샘플의 평균 길이 : 14.501887\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzO6mvX-8E9g"
      },
      "source": [
        "# 토큰화\n",
        "# 높은 빈도수를 갖는 4000개의 단어만을 선택\n",
        "max_words = 4000\n",
        "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYgUPGxC8aNw",
        "outputId": "4686a91d-b79f-4e0d-8bea-ec01b0a1bfdc"
      },
      "source": [
        "vocab_size = max_words\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 4000\n",
            "개체명 태깅 정보 집합의 크기 : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86PrawjZ8dc2"
      },
      "source": [
        "# 정수 인코딩\n",
        "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX8GvoBH8mO-",
        "outputId": "c0e5a306-9f95-4392-ced5-6b8ec94ede84"
      },
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[989, 1, 205, 629, 7, 3939, 216, 1, 3]\n",
            "[4, 1, 7, 1, 1, 1, 7, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEcjwfuT8rKP"
      },
      "source": [
        "# 디코딩 배열\n",
        "index_to_word = src_tokenizer.index_word\n",
        "index_to_ner = tar_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAK0oD5X8zeG",
        "outputId": "284000ff-c5ea-4047-8f7f-34ddf643f531"
      },
      "source": [
        "# 첫 번째 문장 디코딩\n",
        "decoded = []\n",
        "for index in X_train[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
        "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
        "\n",
        "print('기존 문장 : {}'.format(sentences[0]))\n",
        "print('빈도수가 낮은 단어가 OOV 처리된 문장 : {}'.format(decoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존 문장 : ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
            "빈도수가 낮은 단어가 OOV 처리된 문장 : ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCPDgBqP83Gr"
      },
      "source": [
        "# 길이 70으로 padding\n",
        "max_len = 70\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wvvRO6U8_lL"
      },
      "source": [
        "# 데이터 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqhmMQUQ9LLh"
      },
      "source": [
        "# one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhI-j3qm9QBw",
        "outputId": "ac927e14-3e2c-4c51-bff6-eca565ea5b38"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (11232, 70)\n",
            "훈련 샘플 레이블의 크기 : (11232, 70, 10)\n",
            "테스트 샘플 문장의 크기 : (2809, 70)\n",
            "테스트 샘플 레이블의 크기 : (2809, 70, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FtHRZpO9VVp"
      },
      "source": [
        "<ul>\n",
        "<li><h3>양방향 LSTM으로 개체명 인식기 만들기</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glHKn1Ap9Tzi"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0X5fZim9gAV"
      },
      "source": [
        "model = Sequential()\n",
        "# 데이터에서 숫자 0은 연산에서 제외\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))  # LSTM, Many-to-Many\n",
        "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkUyTQC1-Gxo"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxfZWWQ3-IPE",
        "outputId": "f2034a9f-57ed-4cfc-d502-9b3d869d63f9"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=8,  validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "88/88 [==============================] - 24s 97ms/step - loss: 0.1892 - accuracy: 0.8241 - val_loss: 0.1295 - val_accuracy: 0.8332\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 6s 67ms/step - loss: 0.1035 - accuracy: 0.8503 - val_loss: 0.0795 - val_accuracy: 0.8794\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 6s 67ms/step - loss: 0.0697 - accuracy: 0.8971 - val_loss: 0.0577 - val_accuracy: 0.9151\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 6s 69ms/step - loss: 0.0496 - accuracy: 0.9298 - val_loss: 0.0427 - val_accuracy: 0.9403\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 6s 66ms/step - loss: 0.0368 - accuracy: 0.9487 - val_loss: 0.0375 - val_accuracy: 0.9481\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0302 - accuracy: 0.9572 - val_loss: 0.0335 - val_accuracy: 0.9537\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0258 - accuracy: 0.9631 - val_loss: 0.0326 - val_accuracy: 0.9553\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 6s 63ms/step - loss: 0.0225 - accuracy: 0.9680 - val_loss: 0.0320 - val_accuracy: 0.9574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6e216cf10>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES_daC0d-JUO",
        "outputId": "a9d074dd-28aa-4b49-b72c-14120fcbfc79"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0320 - accuracy: 0.9574\n",
            "\n",
            " 테스트 정확도: 0.9574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-ZPT2ab-Pya",
        "outputId": "0cafd77b-086b-410c-8366-2fc930f8e5a7"
      },
      "source": [
        "# 실제 값과 비교해 확인\n",
        "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict(np.array([X_test[i]])) # 예측 y\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 정수 인코딩으로 변경\n",
        "true = np.argmax(y_test[i], -1) # 정수 인코딩으로 변경\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "sarah            : B-PER   B-PER\n",
            "brady            : I-PER   I-PER\n",
            ",                : O       O\n",
            "whose            : O       O\n",
            "republican       : B-MISC  B-MISC\n",
            "husband          : O       O\n",
            "was              : O       O\n",
            "OOV              : O       O\n",
            "OOV              : O       O\n",
            "in               : O       O\n",
            "an               : O       O\n",
            "OOV              : O       O\n",
            "attempt          : O       O\n",
            "on               : O       O\n",
            "president        : O       O\n",
            "ronald           : B-PER   B-PER\n",
            "reagan           : I-PER   I-PER\n",
            ",                : O       O\n",
            "took             : O       O\n",
            "centre           : O       O\n",
            "stage            : O       O\n",
            "at               : O       O\n",
            "the              : O       O\n",
            "democratic       : B-MISC  B-MISC\n",
            "national         : I-MISC  I-MISC\n",
            "convention       : I-MISC  I-MISC\n",
            "on               : O       O\n",
            "monday           : O       O\n",
            "night            : O       O\n",
            "to               : O       O\n",
            "OOV              : O       O\n",
            "president        : O       O\n",
            "bill             : B-PER   B-PER\n",
            "clinton          : I-PER   I-PER\n",
            "'s               : O       O\n",
            "gun              : O       O\n",
            "control          : O       O\n",
            "efforts          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCMdqLUaBJuI"
      },
      "source": [
        "<h2>5. 양방향 LSTM을 이용한 개체명 인식</h2>\n",
        "F1-Score를 사용해 모델을 평가한다.\n",
        "<ul>\n",
        "<li><h3>CRF 사용 조건</h3></li>\n",
        "버전을 맞춰야 원활하게 동작이 가능하다.\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu-i2rx7_4HK",
        "outputId": "5d8d9689-2333-4653-9eeb-6e645529351b"
      },
      "source": [
        "!pip uninstall keras-nightly\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Found existing installation: tensorflow 2.6.0\n",
            "Uninstalling tensorflow-2.6.0:\n",
            "  Successfully uninstalled tensorflow-2.6.0\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 48 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.39.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.6.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.5.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "Successfully installed keras-2.2.4\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "  Downloading tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1 MB 8.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.39.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (4.6.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIVx_wEI8vAz",
        "outputId": "2b54aa87-affa-4d13-cda9-8888019aeb36"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPSnenu6B0Td",
        "outputId": "43cda405-cbf0-4b9c-e28e-96e4e46b5b6b"
      },
      "source": [
        "# keras_contrib 설치 필요\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-hp7upkap\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-hp7upkap\n",
            "Requirement already satisfied: keras in /tensorflow-1.15.2/python3.7 (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=597c6f2d9db8ab910b7f0380e0b9b8d9aa409c5767671243ab8976a67607cd80\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-japu6ij8/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2wQIDXJB4m8"
      },
      "source": [
        "<ul>\n",
        "<li><h3>개체명 인식 데이터에 대한 이해와 전처리</h3></li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYMtkTHUCUya"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "KV4a4We6CXjv",
        "outputId": "8814f2a8-9212-463c-fdb1-95c290083493"
      },
      "source": [
        "data = pd.read_csv(\"/content/ner_dataset.csv\", encoding=\"latin1\")\n",
        "data[:10]\n",
        "# 하나의 문장을 여러 행으로 나눠놓음\n",
        "# \"sentence: k\"가 나오고 NULL이 나오다가 \"sentence: k+1\"이 반복됨"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS    Tag\n",
              "0  Sentence: 1      Thousands  NNS      O\n",
              "1          NaN             of   IN      O\n",
              "2          NaN  demonstrators  NNS      O\n",
              "3          NaN           have  VBP      O\n",
              "4          NaN        marched  VBN      O\n",
              "5          NaN        through   IN      O\n",
              "6          NaN         London  NNP  B-geo\n",
              "7          NaN             to   TO      O\n",
              "8          NaN        protest   VB      O\n",
              "9          NaN            the   DT      O"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UmW6h9zKE6a",
        "outputId": "114a604d-9b78-406a-87e8-bbd1694d3965"
      },
      "source": [
        "print('데이터프레임 행의 개수 : {}'.format(len(data)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터프레임 행의 개수 : 1048575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNpEDCGdKabj",
        "outputId": "f83d4f12-7da7-4fe3-c5b0-190faa89a30a"
      },
      "source": [
        "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무 : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NAuwEErKeOY",
        "outputId": "5f616a79-c028-49b7-aed0-f95219d21979"
      },
      "source": [
        "print('어떤 열에 Null값이 있는지 출력')\n",
        "print('==============================')\n",
        "data.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어떤 열에 Null값이 있는지 출력\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlqA2j4AKg4t",
        "outputId": "70985cb3-ca6c-4869-d598-3f9a9d836345"
      },
      "source": [
        "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
        "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
            "Word 열의 중복을 제거한 값의 개수 : 35178\n",
            "Tag 열의 중복을 제거한 값의 개수 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_MdipdCKnoc",
        "outputId": "6d45ec22-835a-45be-e171-645fb026c833"
      },
      "source": [
        "print('Tag 열의 각각의 값의 개수 카운트')\n",
        "print('================================')\n",
        "print(data.groupby('Tag').size().reset_index(name='count'))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag 열의 각각의 값의 개수 카운트\n",
            "================================\n",
            "      Tag   count\n",
            "0   B-art     402\n",
            "1   B-eve     308\n",
            "2   B-geo   37644\n",
            "3   B-gpe   15870\n",
            "4   B-nat     201\n",
            "5   B-org   20143\n",
            "6   B-per   16990\n",
            "7   B-tim   20333\n",
            "8   I-art     297\n",
            "9   I-eve     253\n",
            "10  I-geo    7414\n",
            "11  I-gpe     198\n",
            "12  I-nat      51\n",
            "13  I-org   16784\n",
            "14  I-per   17251\n",
            "15  I-tim    6528\n",
            "16      O  887908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VrTwWaJKyhe"
      },
      "source": [
        "# Null을 제거(Null을 가진 행의 바로 앞의 행의 값으로 Null을 채운다.)\n",
        "# \"sentence: k\"가 반복적으로 채워진다.\n",
        "data = data.fillna(method=\"ffill\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a9-ksUJLIoF",
        "outputId": "399ce50d-a342-48e7-f71e-18da05ff5af4"
      },
      "source": [
        "print(data.tail())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Sentence #       Word  POS Tag\n",
            "1048570  Sentence: 47959       they  PRP   O\n",
            "1048571  Sentence: 47959  responded  VBD   O\n",
            "1048572  Sentence: 47959         to   TO   O\n",
            "1048573  Sentence: 47959        the   DT   O\n",
            "1048574  Sentence: 47959     attack   NN   O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4lq27_DLKrM",
        "outputId": "2d56f7d0-4f75-4a2a-878b-c85e1a48d27a"
      },
      "source": [
        "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무 : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr3wr8KrLZig",
        "outputId": "01ed1453-02ba-4629-a326-dd9c1b47fdf0"
      },
      "source": [
        "# 단어 소문자화\n",
        "data['Word'] = data['Word'].str.lower()\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 열의 중복을 제거한 값의 개수 : 31817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGBmUvFaLe-a",
        "outputId": "a3a774ec-a977-404e-8a82-8f9371688e24"
      },
      "source": [
        "# 단어, 태깅 정보 매칭\n",
        "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
        "tagged_sentences=[t for t in data.groupby(\"Sentence #\").apply(func)]\n",
        "print(\"전체 샘플 개수: {}\".format(len(tagged_sentences)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수: 47959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCLmuBDRL1Ql",
        "outputId": "a5edfc21-3a9d-4f0c-9dea-787958fb1d5a"
      },
      "source": [
        "print(tagged_sentences[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7B6_rX0MAR1"
      },
      "source": [
        "# 단어와 태깅 정보 분리\n",
        "sentences, ner_tags = [], [] \n",
        "for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n",
        "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
        "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
        "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCVunrV2MH7n",
        "outputId": "6a1b22d4-c979-4b06-83cb-3d98d170a1d0"
      },
      "source": [
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "n3V1wxxUMJ8j",
        "outputId": "f7627f0e-d43a-4f88-9ded-b82a362499ce"
      },
      "source": [
        "# 데이터 길이 분포\n",
        "# 대체로 0~40\n",
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 104\n",
            "샘플의 평균 길이 : 21.863988\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5goxftaWMPzm"
      },
      "source": [
        "# keras tokenizer로 정수 인코딩\n",
        "src_tokenizer = Tokenizer(oov_token='OOV') # 모든 단어를 사용하지만 인덱스 1에는 단어 'OOV'를 할당한다.\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer = Tokenizer(lower=False) # 태깅 정보들은 내부적으로 대문자를 유지한채로 저장\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2yt8Lm2Madl",
        "outputId": "b86e9f55-4fa9-4cad-bb24-9baae7479cac"
      },
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 31819\n",
            "개체명 태깅 정보 집합의 크기 : 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkHan7i3McB7",
        "outputId": "9a1cc877-9301-4d15-f49e-eeca7f438417"
      },
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjYjNHuwMgLk"
      },
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmfx2urdMu_b",
        "outputId": "913a7b7d-3611-48e2-d941-8935e0837532"
      },
      "source": [
        "print(X_data[0])\n",
        "print(y_data[0])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYIvfqmJMyCW"
      },
      "source": [
        "# 모델 훈련 후 결과 확인\n",
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = 'PAD'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzdgysCdM6Y-",
        "outputId": "2245617c-8d3e-4fe6-ed46-e4f20b7e7034"
      },
      "source": [
        "print(index_to_ner)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sxlJ7lUM_GN",
        "outputId": "73b58ef0-f905-4882-be71-3dce0f1ef051"
      },
      "source": [
        "decoded = []\n",
        "for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
        "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
        "\n",
        "print('기존의 문장 : {}'.format(sentences[0]))\n",
        "print('디코딩 문장 : {}'.format(decoded))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13nBiuFDNMJW"
      },
      "source": [
        "# 길이 70으로 패딩\n",
        "max_len = 70\n",
        "# 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
        "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wMMh9RDNTef"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2, random_state=777)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4jqAq8YNW_D"
      },
      "source": [
        "# one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIgcdxyFNaUi",
        "outputId": "fb046c1d-f9c7-4042-ba93-1bc9618fef3a"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_C_11TINdB0"
      },
      "source": [
        "<ul>\n",
        "<li><h3>F1-Score</h3>\n",
        "큰 의미를 갖지 않는 레이블 정보가 대다수의 레이브를 차지하기 때문에 새로운 정확도 측정 방법이 필요하다.<p>\n",
        "정밀도: 특정 개체라고 예측한 것이 일치한 비율<p>\n",
        "재현률: 전체 특정 개체 중 실제 특정 개체라고 맞춘 비율<p>\n",
        "F1-score: 이들의 조화 평균을 구한 것<p>\n",
        "F1-score=2x(정밀도*재현률)/(정밀도+재현률)<p>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxHCJBsBNbc7",
        "outputId": "10028081-4af2-4877-caca-73860fa63a87"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2o4LYSwPCMM"
      },
      "source": [
        "true=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
        "predicted=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXYd_zHpN7WA",
        "outputId": "5bff44f1-731a-44cd-832d-5d3acb38acdd"
      },
      "source": [
        "from seqeval.metrics import classification_report\n",
        "print(classification_report([true], [predicted]))\n",
        "# 정밀도는 1, 재현률을 보면 맞추지 못한 개체가 있다."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       1.00      0.50      0.67         2\n",
            "         PER       1.00      0.67      0.80         3\n",
            "\n",
            "   micro avg       1.00      0.60      0.75         5\n",
            "   macro avg       1.00      0.58      0.73         5\n",
            "weighted avg       1.00      0.60      0.75         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqutCHptP6Ap"
      },
      "source": [
        "<ul>\n",
        "<li><h3>F1-Score callback class</h3>\n",
        "모델을 검증하는 과정에서 F1-socre를 지속적으로 확인하고 F1-score가 가장 높을 때마다 모델 저장\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j9dZLmLOtJo",
        "outputId": "7a715ad7-5b37-45cc-c09e-a7994b70254e"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYuyT9BQW9h"
      },
      "source": [
        "class F1score(Callback):\n",
        "    def __init__(self, value = 0.0, use_char=True):\n",
        "        super(F1score, self).__init__()\n",
        "        self.value = value\n",
        "        self.use_char = use_char\n",
        "\n",
        "    def sequences_to_tags(self, sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
        "      result = []\n",
        "      for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "          tag = []\n",
        "          for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
        "              pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
        "              tag.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD'는 'O'로 변경\n",
        "          result.append(tag)\n",
        "      return result\n",
        "\n",
        "    # 에포크가 끝날 때마다 실행되는 함수\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "      # char Embedding을 사용하는 경우\n",
        "      if self.use_char:\n",
        "        X_test = self.validation_data[0]\n",
        "        X_char_test = self.validation_data[1]\n",
        "        y_test = self.validation_data[2]\n",
        "        y_predicted = self.model.predict([X_test, X_char_test])\n",
        "\n",
        "      else:\n",
        "        X_test = self.validation_data[0]\n",
        "        y_test = self.validation_data[1]\n",
        "        y_predicted = self.model.predict([X_test])\n",
        "\n",
        "      pred_tags = self.sequences_to_tags(y_predicted)\n",
        "      test_tags = self.sequences_to_tags(y_test)\n",
        "\n",
        "      score = f1_score(pred_tags, test_tags)\n",
        "      print(' - f1: {:04.2f}'.format(score * 100))\n",
        "      print(classification_report(test_tags, pred_tags))\n",
        "\n",
        "      # F1-score가 지금까지 중 가장 높은 경우\n",
        "      if score > self.value:\n",
        "        print('f1_score improved from %f to %f, saving model to best_model.h5'%(self.value, score))\n",
        "        self.model.save('best_model.h5')\n",
        "        self.value = score\n",
        "      else:\n",
        "        print('f1_score did not improve from %f'%(self.value))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ_KvQGRQENO"
      },
      "source": [
        "<ul>\n",
        "<li><h3>BiLSTM이용한 개체명인식기</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey9xHfdSQbB9"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwBUJK9aQcXp",
        "outputId": "eebebdc9-a4a7-4909-fb72-3949bc7404fc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNm-sN2MQjRd",
        "outputId": "38f64ef8-4a2d-4d91-f078-964502a7dc10"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=32, epochs=10,  validation_split=0.1, callbacks=[F1score(use_char=False)])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 34530 samples, validate on 3837 samples\n",
            "Epoch 1/10\n",
            "34530/34530 [==============================] - 314s 9ms/step - loss: 0.0923 - accuracy: 0.9253 - val_loss: 0.0466 - val_accuracy: 0.9555\n",
            " - f1: 74.91\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.78      0.86      0.82      3087\n",
            "         gpe       0.89      0.94      0.91      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.61      0.45      0.52      1691\n",
            "         per       0.63      0.69      0.66      1310\n",
            "         tim       0.80      0.79      0.80      1672\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      8989\n",
            "   macro avg       0.46      0.47      0.46      8989\n",
            "weighted avg       0.74      0.75      0.74      8989\n",
            "\n",
            "f1_score improved from 0.000000 to 0.749093, saving model to best_model.h5\n",
            "Epoch 2/10\n",
            "34530/34530 [==============================] - 306s 9ms/step - loss: 0.0364 - accuracy: 0.9649 - val_loss: 0.0402 - val_accuracy: 0.9604\n",
            " - f1: 77.11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.75      0.20      0.32        30\n",
            "         geo       0.80      0.87      0.83      3087\n",
            "         gpe       0.91      0.95      0.93      1146\n",
            "         nat       0.50      0.25      0.33        16\n",
            "         org       0.60      0.55      0.57      1691\n",
            "         per       0.68      0.69      0.69      1310\n",
            "         tim       0.82      0.82      0.82      1672\n",
            "\n",
            "   micro avg       0.77      0.78      0.77      8989\n",
            "   macro avg       0.63      0.54      0.56      8989\n",
            "weighted avg       0.76      0.78      0.77      8989\n",
            "\n",
            "f1_score improved from 0.749093 to 0.771118, saving model to best_model.h5\n",
            "Epoch 3/10\n",
            "34530/34530 [==============================] - 307s 9ms/step - loss: 0.0279 - accuracy: 0.9716 - val_loss: 0.0404 - val_accuracy: 0.9610\n",
            " - f1: 77.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.75      0.20      0.32        30\n",
            "         geo       0.82      0.84      0.83      3087\n",
            "         gpe       0.91      0.94      0.93      1146\n",
            "         nat       1.00      0.25      0.40        16\n",
            "         org       0.58      0.59      0.59      1691\n",
            "         per       0.68      0.72      0.70      1310\n",
            "         tim       0.83      0.82      0.83      1672\n",
            "\n",
            "   micro avg       0.77      0.78      0.78      8989\n",
            "   macro avg       0.70      0.55      0.57      8989\n",
            "weighted avg       0.77      0.78      0.77      8989\n",
            "\n",
            "f1_score improved from 0.771118 to 0.775553, saving model to best_model.h5\n",
            "Epoch 4/10\n",
            "34530/34530 [==============================] - 307s 9ms/step - loss: 0.0232 - accuracy: 0.9759 - val_loss: 0.0421 - val_accuracy: 0.9596\n",
            " - f1: 77.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.50      0.23      0.32        30\n",
            "         geo       0.82      0.84      0.83      3087\n",
            "         gpe       0.89      0.95      0.92      1146\n",
            "         nat       0.50      0.31      0.38        16\n",
            "         org       0.56      0.62      0.59      1691\n",
            "         per       0.66      0.73      0.69      1310\n",
            "         tim       0.85      0.83      0.84      1672\n",
            "\n",
            "   micro avg       0.76      0.79      0.77      8989\n",
            "   macro avg       0.60      0.57      0.57      8989\n",
            "weighted avg       0.76      0.79      0.77      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n",
            "Epoch 5/10\n",
            "34530/34530 [==============================] - 307s 9ms/step - loss: 0.0193 - accuracy: 0.9797 - val_loss: 0.0441 - val_accuracy: 0.9582\n",
            " - f1: 72.69\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.05      0.03      0.04        37\n",
            "         eve       0.24      0.23      0.24        30\n",
            "         geo       0.81      0.84      0.83      3087\n",
            "         gpe       0.90      0.95      0.92      1146\n",
            "         nat       0.71      0.31      0.43        16\n",
            "         org       0.52      0.62      0.57      1691\n",
            "         per       0.69      0.67      0.68      1310\n",
            "         tim       0.54      0.84      0.66      1672\n",
            "\n",
            "   micro avg       0.68      0.78      0.73      8989\n",
            "   macro avg       0.56      0.56      0.55      8989\n",
            "weighted avg       0.70      0.78      0.73      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n",
            "Epoch 6/10\n",
            "34530/34530 [==============================] - 302s 9ms/step - loss: 0.0162 - accuracy: 0.9827 - val_loss: 0.0460 - val_accuracy: 0.9596\n",
            " - f1: 75.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.23      0.14      0.17        37\n",
            "         eve       0.41      0.23      0.30        30\n",
            "         geo       0.80      0.86      0.83      3087\n",
            "         gpe       0.90      0.95      0.92      1146\n",
            "         nat       0.71      0.31      0.43        16\n",
            "         org       0.60      0.56      0.58      1691\n",
            "         per       0.67      0.71      0.69      1310\n",
            "         tim       0.64      0.84      0.73      1672\n",
            "\n",
            "   micro avg       0.72      0.78      0.75      8989\n",
            "   macro avg       0.62      0.58      0.58      8989\n",
            "weighted avg       0.72      0.78      0.75      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n",
            "Epoch 7/10\n",
            "34530/34530 [==============================] - 298s 9ms/step - loss: 0.0133 - accuracy: 0.9862 - val_loss: 0.0512 - val_accuracy: 0.9587\n",
            " - f1: 70.24\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.21      0.16      0.18        37\n",
            "         eve       0.33      0.23      0.27        30\n",
            "         geo       0.82      0.83      0.83      3087\n",
            "         gpe       0.90      0.94      0.92      1146\n",
            "         nat       0.62      0.31      0.42        16\n",
            "         org       0.57      0.57      0.57      1691\n",
            "         per       0.67      0.69      0.68      1310\n",
            "         tim       0.42      0.83      0.56      1672\n",
            "\n",
            "   micro avg       0.64      0.77      0.70      8989\n",
            "   macro avg       0.57      0.57      0.55      8989\n",
            "weighted avg       0.68      0.77      0.71      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n",
            "Epoch 8/10\n",
            "34530/34530 [==============================] - 301s 9ms/step - loss: 0.0107 - accuracy: 0.9887 - val_loss: 0.0547 - val_accuracy: 0.9573\n",
            " - f1: 71.46\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.24      0.14      0.17        37\n",
            "         eve       0.09      0.20      0.12        30\n",
            "         geo       0.77      0.85      0.81      3087\n",
            "         gpe       0.90      0.95      0.92      1146\n",
            "         nat       0.58      0.44      0.50        16\n",
            "         org       0.54      0.56      0.55      1691\n",
            "         per       0.65      0.70      0.68      1310\n",
            "         tim       0.52      0.84      0.64      1672\n",
            "\n",
            "   micro avg       0.66      0.78      0.71      8989\n",
            "   macro avg       0.54      0.58      0.55      8989\n",
            "weighted avg       0.68      0.78      0.72      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n",
            "Epoch 9/10\n",
            "34530/34530 [==============================] - 300s 9ms/step - loss: 0.0085 - accuracy: 0.9911 - val_loss: 0.0603 - val_accuracy: 0.9558\n",
            " - f1: 70.16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.18      0.16      0.17        37\n",
            "         eve       0.24      0.23      0.24        30\n",
            "         geo       0.79      0.85      0.82      3087\n",
            "         gpe       0.88      0.95      0.91      1146\n",
            "         nat       0.80      0.50      0.62        16\n",
            "         org       0.56      0.57      0.56      1691\n",
            "         per       0.68      0.70      0.69      1310\n",
            "         tim       0.42      0.84      0.56      1672\n",
            "\n",
            "   micro avg       0.64      0.78      0.70      8989\n",
            "   macro avg       0.57      0.60      0.57      8989\n",
            "weighted avg       0.67      0.78      0.71      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n",
            "Epoch 10/10\n",
            "34530/34530 [==============================] - 299s 9ms/step - loss: 0.0068 - accuracy: 0.9928 - val_loss: 0.0641 - val_accuracy: 0.9561\n",
            " - f1: 70.45\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.15      0.14      0.14        37\n",
            "         eve       0.26      0.23      0.25        30\n",
            "         geo       0.78      0.84      0.81      3087\n",
            "         gpe       0.89      0.94      0.92      1146\n",
            "         nat       0.67      0.50      0.57        16\n",
            "         org       0.53      0.56      0.54      1691\n",
            "         per       0.67      0.68      0.68      1310\n",
            "         tim       0.47      0.85      0.60      1672\n",
            "\n",
            "   micro avg       0.65      0.77      0.70      8989\n",
            "   macro avg       0.55      0.59      0.56      8989\n",
            "weighted avg       0.67      0.77      0.71      8989\n",
            "\n",
            "f1_score did not improve from 0.775553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U4lWW6oVa6O"
      },
      "source": [
        "<h2>6. 양방향 LSTM과 CRF</h2>\n",
        "<ul>\n",
        "<li><h3>CRF(Conditional Random Field)</h3>\n",
        "활성화 함수의 결과가 CRF 층의 입력으로 전달되어 레이블 시퀀스 중 가장 높은 점수를 갖는 시퀀스를 예측한다.<p>\n",
        "<img src=\"https://wikidocs.net/images/page/34156/bilstmcrf3.PNG\"></img><p>\n",
        "양방향 LSTM은 입력 단어에 대한 양방향 문맥을 반영하고, CRF는 출력 레이블에 대한 양방향 문맥을 반영한다.\n",
        "<li><h3>버전 조건</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgT0D9_NXMYo",
        "outputId": "22e177ef-653c-444a-a842-c0dd576a789e"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow-gpu==1.14.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.39.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: keras-applications\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8\n",
            "Collecting keras==2.2.4\n",
            "  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "Successfully installed keras-2.2.4\n",
            "Requirement already satisfied: tensorflow-gpu==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.39.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI05X7DNXT8E",
        "outputId": "9772fa24-42a9-4b8a-def9-766960e3da98"
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-db0t4yf0\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-db0t4yf0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUBb0xeaXN1q"
      },
      "source": [
        "<ul>\n",
        "<li><h3>개체명 인식 데이터, F1-score callback class</h3>\n",
        "위의 데이터 사용\n",
        "</li>\n",
        "<li><h3>양방향 LSTM+CRF</h3>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpvgipy8XgtE"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras.models import load_model\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLLzF4aBX3vl",
        "outputId": "70a844e6-3730-40e2-b670-004d2cd9abe8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(50, activation=\"relu\")))\n",
        "crf = CRF(tag_size)\n",
        "model.add(crf)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm4GamusdCoS"
      },
      "source": [
        "<h2>7. 양방향 LSTM과 글자 임베딩(Char embedding)</h2>\n",
        "개체명 인식기의 성능을 올리기 위해 워드 임베딩에 글자 임베딩을 연결한다.\n",
        "<ul>\n",
        "<li><h3>글자 임베딩을 위한 전처리</h3>\n",
        "글자 단위 정수 인코딩\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqSx3w5odZme",
        "outputId": "8b5a437b-8ef1-42e7-c435-91e0b05b7914"
      },
      "source": [
        "# char_vocab 만들기\n",
        "words = list(set(data[\"Word\"].values))\n",
        "chars = set([w_i for w in words for w_i in w])\n",
        "chars = sorted(list(chars))\n",
        "print(chars)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge5zSdUCdbhN"
      },
      "source": [
        "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char_to_index[\"OOV\"] = 1\n",
        "char_to_index[\"PAD\"] = 0\n",
        "\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRMVKheFdd5x"
      },
      "source": [
        "max_len_char = 15\n",
        "\n",
        "def padding_char_indice(char_indice, max_len_char):\n",
        "  return pad_sequences(\n",
        "        char_indice, maxlen=max_len_char, padding='post', value = 0)\n",
        "\n",
        "def integer_coding(sentences):\n",
        "  char_data = []\n",
        "  for ts in sentences:\n",
        "    word_indice = [word_to_index[t] for t in ts]\n",
        "    char_indice = [[char_to_index[char] for char in t]  \n",
        "                                          for t in ts]\n",
        "    char_indice = padding_char_indice(char_indice, max_len_char)\n",
        "\n",
        "    for chars_of_token in char_indice:\n",
        "      if len(chars_of_token) > max_len_char:\n",
        "        continue\n",
        "    char_data.append(char_indice)\n",
        "  return char_data"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fj_EhpMdfk6"
      },
      "source": [
        "X_char_data = integer_coding(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P7nauN9dhAt",
        "outputId": "2d225c84-5488-4224-fa96-6c2d80c3fe42"
      },
      "source": [
        "# 기존 문장\n",
        "print(sentences[0])\n",
        "# 단어 인코딩+패딩\n",
        "print(X_data[0])\n",
        "# 글자 인코딩\n",
        "print(X_char_data[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "[ 254    6  967   16 1795  238  468    7  523    2  129    5   61    9\n",
            "  571    2  833    6  186   90   22   15   56    3    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[[53 41 48 54 52 34 47 37 52  0  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 48 47 52 53 51 34 53 48 51 52  0  0]\n",
            " [41 34 55 38  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [46 34 51 36 41 38 37  0  0  0  0  0  0  0  0]\n",
            " [53 41 51 48 54 40 41  0  0  0  0  0  0  0  0]\n",
            " [45 48 47 37 48 47  0  0  0  0  0  0  0  0  0]\n",
            " [53 48  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [49 51 48 53 38 52 53  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 34 51  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 51 34 50  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [34 47 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 34 47 37  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 42 53 41 37 51 34 56 34 45  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [35 51 42 53 42 52 41  0  0  0  0  0  0  0  0]\n",
            " [53 51 48 48 49 52  0  0  0  0  0  0  0  0  0]\n",
            " [39 51 48 46  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 34 53  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [36 48 54 47 53 51 58  0  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwdjn1IRd9iQ",
        "outputId": "4961c41a-4621-4ac6-a738-483c5f2d6bd7"
      },
      "source": [
        "max_len"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6iTF1QQdsSg"
      },
      "source": [
        "# 문장 길이를 70으로 패딩\n",
        "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value = 0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJpZSKfHd_R2"
      },
      "source": [
        "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, y_data, test_size=.2, random_state=777)\n",
        "\n",
        "X_char_train = np.array(X_char_train)\n",
        "X_char_test = np.array(X_char_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x7muCbkeFQY",
        "outputId": "2b602b61-0f6e-4efd-b949-228ba891104e"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 150  928  361   17 2624    9 4131 3567    9    8 2893 1250  880  107\n",
            "    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkGX3g34eHxD",
        "outputId": "f7837016-c2d7-42dd-f0ea-2e5879b6f0f1"
      },
      "source": [
        "print(' '.join([index_to_char[index] for index in X_char_train[0][0]]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s o l d i e r s PAD PAD PAD PAD PAD PAD PAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeYrmO2IYwP6"
      },
      "source": [
        "<ul>\n",
        "<li><h3>BiLSTM-CNN</h3>\n",
        "전처리한 글자 단위 정수 인코딩 입력을 1D CNN의 입력으로 사용해 글자 임베딩을 얻고, 워드 임베딩과 연결해 양방향 LSTM의 입력으로 사용한다.\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H11ci1KfY8yx"
      },
      "source": [
        "from keras.layers import Embedding, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
        "from keras import Input, Model\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.models import load_model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9pa92nYY-hW"
      },
      "source": [
        "# 워드 임베딩\n",
        "word_ids = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "word_embeddings = Embedding(input_dim = vocab_size, output_dim = 64)(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(shape=(None, max_len_char,),name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), 30, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_ids)\n",
        "dropout = Dropout(0.5)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(0.5)(char_embeddings)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 워드 임베딩과 연결\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(50, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='softmax'))(output)\n",
        "\n",
        "model = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam',  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MogXZpZ7B2"
      },
      "source": [
        "<ul>\n",
        "<li><h3>BiLSTM-CNN-CRF</h3>\n",
        "위의 모델에 CRF층을 추가한다.\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dLd6-dLaDOn"
      },
      "source": [
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hloxAhINaGi-"
      },
      "source": [
        "# 워드 임베딩\n",
        "word_ids = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "word_embeddings = Embedding(input_dim = vocab_size, output_dim = 64)(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(shape=(None, max_len_char,),name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), 30, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_ids)\n",
        "dropout = Dropout(0.5)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(0.5)(char_embeddings)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 워드 임베딩과 연결\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(50, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
        "\n",
        "# 출력층에 CRF 층을 추가 (위의 모델과 이 부분이 다릅니다.)\n",
        "output = TimeDistributed(Dense(50, activation='relu'))(output)\n",
        "crf = CRF(tag_size)\n",
        "output = crf(output)\n",
        "\n",
        "model = Model(inputs=[words_input, character_input], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBTzboVaLhI"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "history = model.fit([X_train, X_char_train], y_train, batch_size = 32, epochs = 15, validation_split = 0.1, verbose = 1, callbacks=[F1score(use_char=True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4bAq_NtaPe1"
      },
      "source": [
        "<ul>\n",
        "<li><h3>BiLSTM-BiLSTM-CRF</h3>\n",
        "양방향 LSTM을 이용해 글자 임베딩해서 워드 임베딩과 연결하고 CRF 층을 추가한다.\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dej1ZYIvabxg"
      },
      "source": [
        "# 워드 임베딩\n",
        "word_ids = Input(batch_shape=(None, None), dtype='int32', name='word_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size,\n",
        "                                        output_dim=64,\n",
        "                                        mask_zero=True,\n",
        "                                        name='word_embedding')(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(batch_shape=(None, None, None), dtype='int32', name='char_input')\n",
        "char_embeddings = Embedding(input_dim=(len(char_to_index)),\n",
        "                                        output_dim=30,\n",
        "                                        mask_zero=True,\n",
        "                                        embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5),\n",
        "                                        name='char_embedding')(char_ids)\n",
        "\n",
        "char_embeddings = TimeDistributed(Bidirectional(LSTM(64)))(char_embeddings)\n",
        "\n",
        "# char 임베딩을 워드 임베딩과 연결\n",
        "word_embeddings = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "word_embeddings = Dropout(0.3)(word_embeddings)\n",
        "z = Bidirectional(LSTM(units=64, return_sequences=True))(word_embeddings)\n",
        "z = Dense(tag_size, activation='tanh')(z)\n",
        "crf = CRF(tag_size)\n",
        "output = crf(z)\n",
        "\n",
        "model = Model(inputs=[word_ids, char_ids], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uw_r7ZIaeSZ"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "history = model.fit([X_train, X_char_train], y_train, batch_size = 32, epochs = 15, validation_split = 0.1, verbose = 1, callbacks=[F1score(use_char=True)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}